[Unit]
Description=BenchAI LLM Router - Intelligent Engineering Assistant
After=network.target docker.service
Wants=docker.service

[Service]
Type=simple
User=user
Group=user
WorkingDirectory=/home/user/llama.cpp/router
Environment="PATH=/home/user/.local/bin:/usr/local/bin:/usr/bin:/bin"
Environment="HOME=/home/user"

# Kill any process using port 8085 before starting
ExecStartPre=/bin/bash -c 'fuser -k 8085/tcp 2>/dev/null || true'
ExecStartPre=/bin/sleep 2
ExecStart=/usr/bin/python3 /home/user/llama.cpp/router/llm_router.py
Restart=on-failure
RestartSec=10
TimeoutStopSec=5
KillMode=mixed
StandardOutput=append:/var/log/benchai-router.log
StandardError=append:/var/log/benchai-router.log

# Security hardening
NoNewPrivileges=true
ProtectSystem=strict
ProtectHome=read-only
ReadWritePaths=/home/user/llm-storage /home/user/llama.cpp/router /tmp
PrivateTmp=true

[Install]
WantedBy=multi-user.target
